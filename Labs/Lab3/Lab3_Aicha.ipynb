{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "m1DdRsTqMBgO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"Restaurant reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4OmFvvPNO1r",
        "outputId": "37eb3d6f-508d-4cba-b889-1f9d6bec523d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of             Restaurant              Reviewer  \\\n",
              "0      Beyond Flavours     Rusha Chakraborty   \n",
              "1      Beyond Flavours  Anusha Tirumalaneedi   \n",
              "2      Beyond Flavours       Ashok Shekhawat   \n",
              "3      Beyond Flavours        Swapnil Sarkar   \n",
              "4      Beyond Flavours                Dileep   \n",
              "...                ...                   ...   \n",
              "9995  Chinese Pavilion      Abhishek Mahajan   \n",
              "9996  Chinese Pavilion        Sharad Agrawal   \n",
              "9997  Chinese Pavilion             Ramandeep   \n",
              "9998  Chinese Pavilion       Nayana Shanbhag   \n",
              "9999  Chinese Pavilion      Bhargava Krishna   \n",
              "\n",
              "                                                 Review Rating  \\\n",
              "0     The ambience was good, food was quite good . h...      5   \n",
              "1     Ambience is too good for a pleasant evening. S...      5   \n",
              "2     A must try.. great food great ambience. Thnx f...      5   \n",
              "3     Soumen das and Arun was a great guy. Only beca...      5   \n",
              "4     Food is good.we ordered Kodi drumsticks and ba...      5   \n",
              "...                                                 ...    ...   \n",
              "9995  Madhumathi Mahajan Well to start with nice cou...      3   \n",
              "9996  This place has never disappointed us.. The foo...    4.5   \n",
              "9997  Bad rating is mainly because of \"Chicken Bone ...    1.5   \n",
              "9998  I personally love and prefer Chinese Food. Had...      4   \n",
              "9999  Checked in here to try some delicious chinese ...    3.5   \n",
              "\n",
              "                          Metadata             Time  Pictures    7514  \n",
              "0           1 Review , 2 Followers  5/25/2019 15:54         0  2447.0  \n",
              "1          3 Reviews , 2 Followers  5/25/2019 14:20         0     NaN  \n",
              "2          2 Reviews , 3 Followers  5/24/2019 22:54         0     NaN  \n",
              "3            1 Review , 1 Follower  5/24/2019 22:11         0     NaN  \n",
              "4          3 Reviews , 2 Followers  5/24/2019 21:37         0     NaN  \n",
              "...                            ...              ...       ...     ...  \n",
              "9995     53 Reviews , 54 Followers    6/5/2016 0:08         0     NaN  \n",
              "9996      2 Reviews , 53 Followers   6/4/2016 22:01         0     NaN  \n",
              "9997    65 Reviews , 423 Followers   6/3/2016 10:37         3     NaN  \n",
              "9998    13 Reviews , 144 Followers  5/31/2016 17:22         0     NaN  \n",
              "9999  472 Reviews , 1302 Followers  5/31/2016 16:41         6     NaN  \n",
              "\n",
              "[10000 rows x 8 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "\n",
        "Split data into training and testing with 80/20 split"
      ],
      "metadata": {
        "id": "RyRyFv1QOH32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[:8000]\n",
        "train.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI3NgZPQN05k",
        "outputId": "4387bb42-988a-40e2-ab62-af5d800d513a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of            Restaurant              Reviewer  \\\n",
              "0     Beyond Flavours     Rusha Chakraborty   \n",
              "1     Beyond Flavours  Anusha Tirumalaneedi   \n",
              "2     Beyond Flavours       Ashok Shekhawat   \n",
              "3     Beyond Flavours        Swapnil Sarkar   \n",
              "4     Beyond Flavours                Dileep   \n",
              "...               ...                   ...   \n",
              "7995     Olive Garden        Monika Chunchu   \n",
              "7996     Olive Garden        Abhishek Kumar   \n",
              "7997     Olive Garden               Deepika   \n",
              "7998     Olive Garden           Sneha Gupta   \n",
              "7999     Olive Garden          RASHMI SINGH   \n",
              "\n",
              "                                                 Review Rating  \\\n",
              "0     The ambience was good, food was quite good . h...      5   \n",
              "1     Ambience is too good for a pleasant evening. S...      5   \n",
              "2     A must try.. great food great ambience. Thnx f...      5   \n",
              "3     Soumen das and Arun was a great guy. Only beca...      5   \n",
              "4     Food is good.we ordered Kodi drumsticks and ba...      5   \n",
              "...                                                 ...    ...   \n",
              "7995                                          very nice      5   \n",
              "7996                                gajar halwa was bad      3   \n",
              "7997  sweet was not served with ordered veg executiv...      3   \n",
              "7998  the dish was extremely oily. the tandoori roti...      2   \n",
              "7999                          food and packing was good      4   \n",
              "\n",
              "                        Metadata             Time  Pictures    7514  \n",
              "0         1 Review , 2 Followers  5/25/2019 15:54         0  2447.0  \n",
              "1        3 Reviews , 2 Followers  5/25/2019 14:20         0     NaN  \n",
              "2        2 Reviews , 3 Followers  5/24/2019 22:54         0     NaN  \n",
              "3          1 Review , 1 Follower  5/24/2019 22:11         0     NaN  \n",
              "4        3 Reviews , 2 Followers  5/24/2019 21:37         0     NaN  \n",
              "...                          ...              ...       ...     ...  \n",
              "7995                    1 Review   7/5/2018 23:25         0     NaN  \n",
              "7996     19 Reviews , 1 Follower   7/4/2018 19:48         0     NaN  \n",
              "7997      3 Reviews , 1 Follower   7/4/2018 14:08         0     NaN  \n",
              "7998  10 Reviews , 119 Followers    7/2/2018 0:19         0     NaN  \n",
              "7999                   2 Reviews   7/1/2018 14:22         0     NaN  \n",
              "\n",
              "[8000 rows x 8 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal** : Predict the the rating based on the reviews\n",
        "\n",
        "**Sentiment analysis:** determines the emotional tone or sentiment expressed in text."
      ],
      "metadata": {
        "id": "8ag744LCPRoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = df[8000:10000]\n",
        "test.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzxLJ0NNQr7S",
        "outputId": "b38c3c5a-d10f-4f7b-be52-67bf48485db7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                Restaurant          Reviewer  \\\n",
              "8000  Tandoori Food Works      Asha Akunuri   \n",
              "8001  Tandoori Food Works    Krishnakanth M   \n",
              "8002  Tandoori Food Works             Gauri   \n",
              "8003  Tandoori Food Works         Ravi Teja   \n",
              "8004  Tandoori Food Works      Neeraj Sethi   \n",
              "...                   ...               ...   \n",
              "9995     Chinese Pavilion  Abhishek Mahajan   \n",
              "9996     Chinese Pavilion    Sharad Agrawal   \n",
              "9997     Chinese Pavilion         Ramandeep   \n",
              "9998     Chinese Pavilion   Nayana Shanbhag   \n",
              "9999     Chinese Pavilion  Bhargava Krishna   \n",
              "\n",
              "                                                 Review Rating  \\\n",
              "8000  Very less priced restaurant located in SLN ter...      4   \n",
              "8001  Very pleasant experience at TFW. The stuffed t...      4   \n",
              "8002  Ordered chicken tikka from here. Never had itn...      2   \n",
              "8003  Thank you to this restaurant. I got 2 biryanis...      4   \n",
              "8004  Good biryani. if you love kind of more burn an...      4   \n",
              "...                                                 ...    ...   \n",
              "9995  Madhumathi Mahajan Well to start with nice cou...      3   \n",
              "9996  This place has never disappointed us.. The foo...    4.5   \n",
              "9997  Bad rating is mainly because of \"Chicken Bone ...    1.5   \n",
              "9998  I personally love and prefer Chinese Food. Had...      4   \n",
              "9999  Checked in here to try some delicious chinese ...    3.5   \n",
              "\n",
              "                          Metadata             Time  Pictures  7514  \n",
              "8000     47 Reviews , 60 Followers  5/20/2019 11:53         2   NaN  \n",
              "8001        5 Reviews , 1 Follower  5/14/2019 21:09         0   NaN  \n",
              "8002     31 Reviews , 21 Followers  5/12/2019 23:54         0   NaN  \n",
              "8003                     5 Reviews   5/11/2019 2:12         0   NaN  \n",
              "8004       4 Reviews , 4 Followers   5/10/2019 0:43         0   NaN  \n",
              "...                            ...              ...       ...   ...  \n",
              "9995     53 Reviews , 54 Followers    6/5/2016 0:08         0   NaN  \n",
              "9996      2 Reviews , 53 Followers   6/4/2016 22:01         0   NaN  \n",
              "9997    65 Reviews , 423 Followers   6/3/2016 10:37         3   NaN  \n",
              "9998    13 Reviews , 144 Followers  5/31/2016 17:22         0   NaN  \n",
              "9999  472 Reviews , 1302 Followers  5/31/2016 16:41         6   NaN  \n",
              "\n",
              "[2000 rows x 8 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train['Review']\n",
        "y_train = train['Rating'].apply(str)\n",
        "x_train[0]\n",
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hm6PkIMjN7R9",
        "outputId": "2fad65f5-21c7-4d25-8ec5-7d1d4de99007"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test['Review']\n",
        "y_test = test['Rating'].apply(str)\n",
        "x_test[8000]\n",
        "y_test[8000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1dk7FQO0R5i9",
        "outputId": "6089c0a0-6ad3-42a1-c16a-9414dc9c7b39"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Are we dealing with supervised or unsupervised learning?** Supervised"
      ],
      "metadata": {
        "id": "Ce3zu0V7PBza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2**\n",
        "\n",
        "Imports and Initialisation"
      ],
      "metadata": {
        "id": "8YybSSQ3RTMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "\n",
        "import re\n",
        "\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tokenizer=RegexpTokenizer(r'\\w+')\n",
        "en_stopwords=set(stopwords.words('english'))\n",
        "ps=PorterStemmer()\n",
        "wnet = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV9RRpFgRSMw",
        "outputId": "7f4e4dd6-b3ae-4290-e1f5-01811ca23449"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a token for us?** words"
      ],
      "metadata": {
        "id": "qLEjozP8TRWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3**\n",
        "\n",
        "Text Cleaning"
      ],
      "metadata": {
        "id": "RO3OUYqiTxm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove emojis\n",
        "\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)"
      ],
      "metadata": {
        "id": "aKXrQGMNi0nB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanText(text):\n",
        "\n",
        "  #step 1 lowering\n",
        "\n",
        "  text.lower()\n",
        "\n",
        "  # step 2 remove emojis\n",
        "\n",
        "  text = remove_emojis(text)\n",
        "\n",
        "  #step 3 stem words\n",
        "\n",
        "  stem_list = [ps.stem(word) for word in text.split()]\n",
        "  text = ''.join(ps.stem(word) for word in text)\n",
        "\n",
        "  #step 4 lemmetaization\n",
        "  lemm_list = [wnet.lemmatize(word) for word in text.split()]\n",
        "  text = ''.join(wnet.lemmatize(word) for word in text)\n",
        "\n",
        "  #step 5 stopwords\n",
        "\n",
        "  # list to add filtered words from review\n",
        "  filtered_text = []\n",
        "  # verify & append words from the text to filtered_text list\n",
        "  for word in text.split():\n",
        "      if word not in en_stopwords:\n",
        "        filtered_text.append(word)\n",
        "  # add content from filtered_text list to new variable\n",
        "  clean_review = filtered_text[:]\n",
        "  # emptying the filtered_text list for new review\n",
        "  filtered_text.clear()\n",
        "\n",
        "  return ' '.join(clean_review)\n"
      ],
      "metadata": {
        "id": "bT7xbtSFTvyT"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4\n",
        "cleaing x and x_test using the function we created"
      ],
      "metadata": {
        "id": "Pg119RPljYxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_str = x_train.apply(str)\n",
        "xt_str = x_test.apply(str)"
      ],
      "metadata": {
        "id": "VlIfQsR0F2qm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_clean = x_str.apply(cleanText)\n",
        "xt_clean = xt_str.apply(cleanText)"
      ],
      "metadata": {
        "id": "8eNoDntaXuQm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S19z4aRRXteJ",
        "outputId": "ce5849b6-e974-4784-b66d-f18ac380b050"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ambience good, food quite good . saturday lunc...\n",
              "1       ambience good pleasant evening. service prompt...\n",
              "2       must try.. great food great ambience. thnx ser...\n",
              "3       soumen das arun great guy. behavior sincerety,...\n",
              "4       food good.we ordered kodi drumsticks basket mu...\n",
              "                              ...                        \n",
              "7995                                                 nice\n",
              "7996                                      gajar halwa bad\n",
              "7997          sweet served ordered veg executive meal box\n",
              "7998    dish extremely oily. tandoori roti tasting sou...\n",
              "7999                                    food packing good\n",
              "Name: Review, Length: 8000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xt_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY5JEAiDX0aw",
        "outputId": "f3402a85-a736-492d-e0b7-35544c08e9e0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000    less priced restaurant located sln terminus. o...\n",
              "8001    pleasant experience tfw. stuffed tangdi kabab ...\n",
              "8002    ordered chicken tikka here. never itna oily ch...\n",
              "8003    thank restaurant. got 2 biryanis using gold su...\n",
              "8004    good biryani. love kind burn spicy try one. lo...\n",
              "                              ...                        \n",
              "9995    madhumathi mahajan well start nice courteous s...\n",
              "9996    place never disappointed us.. food, courteous ...\n",
              "9997    bad rating mainly \"chicken bone found veg food...\n",
              "9998    personally love prefer chinese food. couple ti...\n",
              "9999    checked try delicious chinese food here, seen ...\n",
              "Name: Review, Length: 2000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5\n",
        "\n",
        "vectorizing our text for analysis"
      ],
      "metadata": {
        "id": "MwFQMYkBjjLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv=CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "x_vec=cv.fit_transform(x_clean).toarray()\n",
        "\n",
        "x_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiIW41xZjTpt",
        "outputId": "1e18d2fe-2dcc-4365-889c-64e1d96614a3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 6\n",
        "extracting the feature vector\n",
        "\n",
        "**Which n-gram did you use? What does it mean?** We used both unigrams and bigrams which means our features are composed of 1 to 2 words or charcters."
      ],
      "metadata": {
        "id": "nSpLw0jljxfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmZ8pa54jsjH",
        "outputId": "58dda637-8e54-4954-bd67-277ef037d5f4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['00', '00 complete', '00 near', ..., 'ànd dum', 'éclat',\n",
              "       'éclat average'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 7\n",
        "\n",
        "Transforming x_test"
      ],
      "metadata": {
        "id": "eZ39MgNVk1XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xt_vec=cv.transform(xt_clean).toarray()"
      ],
      "metadata": {
        "id": "TfwvtBczkuFH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 8\n",
        "\n",
        "classifiying our text\n",
        "\n",
        "**y_pred** : Represents the predicted rating based on the sentiment analysis and text classification using naive bayes of the customers reviews. The model provided an accuracy of **0.557** in terms of predicting customers rating based on tehir reviews."
      ],
      "metadata": {
        "id": "rMvs1qErlW-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#this version of naive bayes is used for text classification\n",
        "\n",
        "mn=MultinomialNB()\n",
        "\n",
        "mn.fit(x_vec,y_train)\n",
        "\n",
        "y_pred=mn.predict(xt_vec)\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wITBsYllfLO",
        "outputId": "366f9d35-daf4-4f6e-e412-e4aca553fad1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['4', '4', '1', ..., '4', '4', '4'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZoezEJvHdzX",
        "outputId": "b9494e42-cf0b-4933-a381-3a274ec2d5bb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.557\n"
          ]
        }
      ]
    }
  ]
}